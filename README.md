<h1> ğŸ“š Books Online - Scraper de Prix </h1>

<h2>Automatisation du suivi des prix des livres dâ€™occasion</h2>
<h3>Un projet Python pour extraire les prix des livres de Books to Scrape</h3>

<br>

<h3>ğŸ“ Description du projet</h3>

Ce projet vise Ã  automatiser la surveillance des prix des livres dâ€™occasion sur le site [Books to Scrape](https://books.toscrape.com) afin dâ€™aider Books Online, une librairie en ligne, Ã  mieux suivre la concurrence.

Le programme est un scraper Python qui extrait les informations tarifaires et les enregistre sous forme exploitable pour des analyses ultÃ©rieures.

<h4>ğŸ¯ Objectifs</h4>
<li>Automatiser la collecte des prix des livres sur Books to Scrape.</li>
<li>Structurer les donnÃ©es extraites sous un format exploitable (CSV/JSON).</li>
<li>PrÃ©parer le terrain pour un futur pipeline ETL.</li>

<h4>ğŸ“‚ Contenu du repository</h4>
<li>scraper.py â†’ Script principal qui extrait les donnÃ©es.</li>
<li>requirements.txt â†’ Liste des dÃ©pendances Ã  installer.</li>
<li>README.md â†’ Ce fichier expliquant le projet.</li>
<li>.gitignore â†’ Exclut les fichiers temporaires et les donnÃ©es extraites.</li>

<h4>ğŸ› ï¸ Installation et exÃ©cution</h4>

1. PrÃ©-requis

Assurez-vous dâ€™avoir Python 3.x installÃ©. VÃ©rifiez avec :

<code>python --version</code>

2. Installation des dÃ©pendances

Clonez ce repository et installez les modules nÃ©cessaires :

<code>git clone https://github.com/sRuiiit/BookPriceScraper.git
cd books-online-scraper
pip install -r requirements.txt</code>

3. Lancer le scraper

ExÃ©cutez le script :

<code>python scraper.py</code>

Cela gÃ©nÃ©rera un dossier CSVparcategories contenant un fichier CSV par catÃ©gorie lui-mÃªme contenant les informations des livres extraits.

<h4>ğŸ“Š Format des donnÃ©es extraites</h4>

Les donnÃ©es sont enregistrÃ©es sous forme de fichier CSV avec les colonnes suivantes :

| Titre    | Prix   | DisponibilitÃ© |
|----------|--------|--------------|
| Book 1   | 45.99â‚¬ | En stock     |
| Book 2   | 12.50â‚¬ | En stock     |

<h4>ğŸ”§ Vers un pipeline ETL</h4>

Pour aller plus loin, ce scraper pourrait Ãªtre intÃ©grÃ© dans un pipeline ETL en plusieurs Ã©tapes :
<li>Extract â†’ Extraction des donnÃ©es via ce scraper.</li>
<li>Transform â†’ Nettoyage et enrichissement des donnÃ©es (ex. conversion des devises).</li>
<li>Load â†’ Chargement des donnÃ©es dans une base de donnÃ©es ou un tableau dâ€™analyse.</li>
<br>
Lâ€™utilisation de cron jobs ou dâ€™un scheduler Python permettrait dâ€™automatiser ce processus.

<h4>ğŸš€ AmÃ©liorations futures</h4>
<li>Ajouter des librairies concurrentes pour Ã©largir le suivi des prix.</li>
<li>Automatiser le scraping Ã  intervalles rÃ©guliers.</li>
<li>Stocker les donnÃ©es dans une base SQL ou un tableau interactif.</li>
<li>IntÃ©grer une visualisation des tendances de prix.</li>
<li>Utiliser la librairie LXML plus rapide et robuste.</li>

<h4>ğŸ‘¤ Auteur</h4>

Steve Raffner
ğŸ“© Contact : claudefrancois@gmail.com
ğŸ”— GitHub : https://github.com/sRuiiit

ğŸ’¡ Nâ€™hÃ©sitez pas Ã  contribuer ou Ã  poser des questions ! ğŸš€
